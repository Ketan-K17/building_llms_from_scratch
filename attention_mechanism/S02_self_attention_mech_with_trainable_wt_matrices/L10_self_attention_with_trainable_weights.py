# This self-attention mechanism is also called 'Scaled Dot-Product Attention'.

# these trainable weight matrices are in 3 types: 'query' (Wq), 'key' (Wk), and 'value' (Wv) matrices. They are created during model training.
